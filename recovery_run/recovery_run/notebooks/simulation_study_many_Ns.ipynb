{
 "metadata": {
  "name": "",
  "signature": "sha256:12c89d2eb037c96ef4922ed86fe424411adf3fbc586211f8894a8c8220c9ecb6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.random.seed(42)\n",
      "import python_utils.python_utils.caching as caching\n",
      "import recovery_run.recovery_run.constants as constants\n",
      "caching.init(constants.cache_folder, constants.which_hash)\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import matplotlib\n",
      "from IPython.display import display_pretty, display_html\n",
      "import python_utils.python_utils.basic as basic\n",
      "import recovery_curve.recovery_curve.utils as recovery_utils\n",
      "import recovery_curve.recovery_curve.fxns as recovery_fxns\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import functools\n",
      "import operator\n",
      "import pdb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the distribution used for inference\n",
      "s_a, s_b, s_c = 1., 1., 1.\n",
      "l_a, l_b, l_c = 10., 10., 10.\n",
      "K = 1\n",
      "l_a_dist = recovery_utils.frozen_dist(functools.partial(recovery_utils.sample_truncated_exponential,l=l_a))\n",
      "l_b_dist = recovery_utils.frozen_dist(functools.partial(recovery_utils.sample_truncated_exponential,l=l_b))\n",
      "l_c_dist = recovery_utils.frozen_dist(functools.partial(recovery_utils.sample_truncated_exponential,l=l_c))\n",
      "B_phis_dist = recovery_fxns.B_phis_dist(s_a, s_b, s_c, l_a_dist, l_b_dist, l_c_dist, K)\n",
      "pop_a, pop_b, pop_c = 0.3, 0.6, 5.\n",
      "a_dist = recovery_fxns.a_dist(pop_a)\n",
      "b_dist = recovery_fxns.b_dist(pop_b)\n",
      "c_dist = recovery_fxns.c_dist(pop_c)\n",
      "abc_ns_dist = recovery_fxns.abc_ns_dist(a_dist, b_dist, c_dist)\n",
      "l_m = 10.\n",
      "noise_dist_dist = recovery_fxns.noise_dist_dist(l_m)\n",
      "everything_dist = recovery_fxns.everything_dist(B_phis_dist, abc_ns_dist, noise_dist_dist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define sizes of datasets\n",
      "#Ns = [50,100,250,500,1000]\n",
      "Ns = [500,1000,2500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the that simulates true data\n",
      "stdev = 1.\n",
      "b_a = -.5\n",
      "b_b = .5\n",
      "b_c = .5\n",
      "phi_a, phi_b, phi_c = 0.01, 0.01, 0.01\n",
      "theta = 0.1\n",
      "p = 0.3\n",
      "phi_m = 0.01\n",
      "def simulate_true_data(N):\n",
      "    x_ns_true = recovery_fxns.simulate_xs(N, K, stdev)\n",
      "    ts = np.array([1,2,4,8,12,18,24,30,36,42])\n",
      "    ts_ns_true = np.array([ts for i in xrange(N)])\n",
      "    s_ns_true = np.random.uniform(size=N)\n",
      "    B_a = b_a * np.ones(K)\n",
      "    B_b = b_b * np.ones(K)\n",
      "    B_c = b_c * np.ones(K)\n",
      "    constant_B_phis_dist = recovery_utils.constant_dist(recovery_fxns.B_phis(B_a, B_b, B_c, phi_a, phi_b, phi_c))\n",
      "    constant_abc_ns_dist = abc_ns_dist # this means abc_ns_dist does not contain within it a source of randomness, ie f(x;g); g is random\n",
      "    constant_noise_dist_dist = recovery_utils.constant_dist(recovery_fxns.noise_dist(theta,p,phi_m))\n",
      "    constant_everything_dist = recovery_fxns.everything_dist(constant_B_phis_dist, constant_abc_ns_dist, constant_noise_dist_dist)\n",
      "    everything_sample = constant_everything_dist.sample(s_ns_true, x_ns_true, ts_ns_true)\n",
      "    ys_ns_sample_true = everything_sample.ys_ns\n",
      "    return s_ns_true, x_ns_true, ts_ns_true, ys_ns_sample_true"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define parameters for getting traces\n",
      "n_steps = 5000\n",
      "random_seed = 42"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loop through N_noises, generate data, fit, store samples in a dataframe for each parameter\n",
      "\n",
      "big_param_info = [\\\n",
      "              ('$b_A$', 'B_a',b_a,'r'),\\\n",
      "              ('$b_B$','B_b',b_b,'b'),\\\n",
      "              ('$b_C$','B_c',b_c,'k'),\\\n",
      "              ('$\\Theta$','theta',theta,'g'),\\\n",
      "              ('$p$','p',p,'y')\\\n",
      "              ]\n",
      "big_param_samples = {param:pd.DataFrame() for param in map(operator.itemgetter(1), big_param_info)}\n",
      "\n",
      "small_param_info = [\\\n",
      "                    ('$\\phi_A$','phi_a',phi_a,'r'),\\\n",
      "                    ('$\\phi_B$','phi_b',phi_b,'b'),\\\n",
      "                    ('$\\phi_C$','phi_c',phi_c,'k'),\\\n",
      "                    ('$\\phi_M$','phi_m',phi_m,'g')\\\n",
      "                    ]\n",
      "small_param_samples = {param:pd.DataFrame() for param in map(operator.itemgetter(1), small_param_info)}\n",
      "\n",
      "big_fig, big_ax = plt.subplots()\n",
      "small_fig, small_ax = plt.subplots()\n",
      "\n",
      "for N in Ns:\n",
      "    \n",
      "    s_ns, x_ns, ts_ns, ys_ns_sample = simulate_true_data(N)\n",
      "    \n",
      "    traces = recovery_fxns.get_everything_dist_traces_helper(n_steps, random_seed, everything_dist, s_ns, x_ns, ts_ns, ys_ns_sample)\n",
      "    \n",
      "    for (display_name,param_name,true_val,color) in big_param_info:\n",
      "        raw_samples = traces.param_to_trace(param_name)\n",
      "        samples = raw_samples.reshape(raw_samples.shape[0]) - true_val\n",
      "        big_ax.scatter([N], np.mean(samples), color=color)\n",
      "        big_param_samples[param_name][N] = samples\n",
      "        \n",
      "    for (display_name,param_name,true_val,color) in small_param_info:\n",
      "        raw_samples = traces.param_to_trace(param_name)\n",
      "        samples = raw_samples.reshape(raw_samples.shape[0]) - true_val\n",
      "        small_ax.scatter([N], np.mean(samples), color=color)\n",
      "        small_param_samples[param_name][N] = samples\n",
      "\n",
      "        \n",
      "    lower_q = 25\n",
      "    upper_q = 75\n",
      "    for (display_name,param_name,true_val,color) in big_param_info:\n",
      "        means = big_param_samples[param_name].mean(axis=0)\n",
      "        lower = big_param_samples[param_name].apply(lambda x:np.percentile(x,lower_q))\n",
      "        upper = big_param_samples[param_name].apply(lambda x:np.percentile(x,upper_q))\n",
      "        big_ax.plot(means.index, means, label=display_name, color=color)\n",
      "        big_ax.plot(lower.index, lower, ls='--', color=color)\n",
      "        big_ax.plot(upper.index, upper, ls='--', color=color)\n",
      "    \n",
      "    for (display_name,param_name,true_val,color) in small_param_info:\n",
      "        means = small_param_samples[param_name].mean(axis=0)\n",
      "        lower = small_param_samples[param_name].apply(lambda x:np.percentile(x,lower_q))\n",
      "        upper = small_param_samples[param_name].apply(lambda x:np.percentile(x,upper_q))\n",
      "        small_ax.plot(means.index, means, label=display_name, color=color)\n",
      "        small_ax.plot(lower.index, lower, ls='--', color=color)\n",
      "        small_ax.plot(upper.index, upper, ls='--', color=color)\n",
      "    \n",
      "    big_ax.legend(prop={'size':constants.legend_fontsize})\n",
      "    small_ax.legend(prop={'size':constants.legend_fontsize})\n",
      "    big_ax.set_title('error vs number of simulated data',fontsize=constants.title_fontsize)\n",
      "    big_ax.set_xlabel('number of samples',fontsize=constants.label_fontsize)\n",
      "    big_ax.set_ylabel('error',fontsize=constants.label_fontsize)\n",
      "    big_ax.tick_params(axis='both', which='major', labelsize=constants.tick_fontsize)\n",
      "    big_ax.tick_params(axis='both', which='minor', labelsize=constants.tick_fontsize)\n",
      "    big_fig.tight_layout()\n",
      "    small_ax.set_title('error vs number of simulated data',fontsize=constants.title_fontsize)\n",
      "    small_ax.set_xlabel('number of samples',fontsize=constants.label_fontsize)\n",
      "    small_ax.set_ylabel('error',fontsize=constants.label_fontsize)\n",
      "    small_ax.tick_params(axis='both', which='major', labelsize=constants.tick_fontsize)\n",
      "    small_ax.tick_params(axis='both', which='minor', labelsize=constants.tick_fontsize)\n",
      "    small_fig.tight_layout()\n",
      "    basic.display_fig_inline(big_fig)\n",
      "    basic.display_fig_inline(small_fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}